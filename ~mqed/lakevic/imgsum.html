<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html>

	<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
		<meta name="generator" content="Adobe GoLive 6">
		<title>Classified Image Process Summary</title>
	</head>

	<body bgcolor="#ffffff">
		<div align="center">
			<h2><a name="top"></a>Processing of Remote Sensing Imagery To Produce Water Hyacinth Coverage Data</h2>
		</div>
		<div align="left">
			<p><a href="index.html">Back to Overview</a></p>
			<p>[This summary is based on Albright, Moorhouse, and McNabb 2002, pp. 8-16.]</p>
			<p>Cloud-free (or, in the case of radar sensor technology, otherwise unimpeded) imagery was obtained from a variety of sensors, over various time periods and at a number of different resolutions. Sensors used included <a href="http://edc.usgs.gov/glis/hyper/guide/landsat_tm">Landsat TM</a>, <a href="http://www.space.gc.ca/csa_sectors/earth_environment/radarsat/radarsat_info/default.asp">Radarsat</a>, <a href="http://landsat.gsfc.nasa.gov/">Landsat 7 ETM+</a>, <a href="http://www.eorc.nasda.go.jp/JERS-1/">JERS SAR</a>, and <a href="http://www.spaceimagingme.com/content/Constellation/IKONOS/index.asp">Iknonos</a>. Image resolution ranged from 1 m to 100 m. Data were gathered mostly in the visible and near infrared part of the spectrum, but two sensors (JERS and Radarsat) used radar sensor technology.</p>
		</div>
		<p>The extraction of information on water hyacinth extent and distribution from the imagery proceeded according to the accompanying flow chart:</p>
		<div align="center">
			<p><img src="http://www.math.dartmouth.edu/~mqed/lakevic/graphics/figure2.gif" alt="" height="750" width="563" border="1"></p>
		</div>
		<div align="right">
			<p>(Redrawn from Albright, Moorhouse, and McNabb 2002)</p>
		</div>
		<div align="left">
			<p>The raw imagery was mosaiced together, and this reference mosaic was used to place the individual images into a uniform projection (UTM zone 36, WGS84 datum). The researchers then created a layer (called the &quot;water mask&quot;) to eliminate land and permanent aquatic vegetation from further analysis. They then processed the masked imagery using a variety of image analysis classification techniques to identify potential water hyacinth (WH) pixels. (The particular technique used on each image depended on the sensor technology involved.) These preliminary images then underwent manual editing and/or image filtering to refine the classification into WH and non-WH. The result at this stage was a set of classified WH imagery. The researchers then analyzed the imagery by geographic unit (bays and gulfs within Lake Victoria) in order to produce a set of summary statistics describing the situation in each of the geographic units. (The geographic unit masks used to isolate these areas had been developed using a combination of reference masks and the water mask.)</p>
			<h4>Reference</h4>
			<p>Albright, Thomas, Thomas Moorhouse, and Thomas McNabb. 2002. The Abundance and Distribution of Water Hyacinth in Lake Victoria and the Kagera River Basin, 1989-2001. USGS/EROS Data Center and Clean Lakes, Inc. &lt;http://edcintl.cr.usgs.gov/lakespecialfeature.html&gt;</p>
			<p><a href="imgsum.html#top">Top</a> | <a href="index.html">Back to Overview</a></p>
		</div>
		<div align="right">
			<p></p>
		</div>
	</body>

</html>