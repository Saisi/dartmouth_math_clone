<html>

<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<title>Linear and Nonlinear Regression</title>
</head>

<body bgcolor="#FFFFFF" text="#000000">

<p align="center"><font size="5">Linear and Nonlinear Regression</font></p>

<p align="center"><font size="4"><i>Eugene Demidenko</i></font></p>

<p align="center">Financi &amp; Statistica, Moscow 1981</p>

<p align="center">(in Russian)</p>

<p align="center">&nbsp;</p>

<p>Principles of regression analysis are considered in this book. Assumptions and possible
violations are analyzed. Alternative regression schemes and methods of estimations are
discussed. In particular, regression with stochastic independent variables, as conditional
mean, is distinguished. Nonstandard methods of estimation include: errors-in-variables,
robust and M-estimation, estimation under multicollinearity, seemingly unrelated
regressions, nonlinear regression. The text may be used by researchers in application of
regression analysis or it may be used as the basis of a teaching course in statistics for
undergraduate/graduate students.</p>

<p>&nbsp;</p>

<p align="center"><font size="4"><b>Table of Contents</b></font></p>

<p><strong>Preface</strong></p>

<p>&nbsp;</p>

<p><font size="5">Part 1. Linear Regression as unconditional mean</font></p>

<p><b>Chapter 1. Classical regression. Properties of the Ordinary Least Squares Estimator</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.1 Main assumptions. The OLS-estimator 5</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.2 Geometry of the OLS-estimator 15</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.3 Discussion of classical regression
assumptions 16</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.4 Methodology of statistical estimation 20</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.5 Gauss-Markov Theorem 29</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.6 Coefficient of determination and its
interpretation 34</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.7 Consistency and normality of the
OLS-estimator 41</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.8 Properties of the OLS-estimator under
assumption of normality 51</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.9 General principles of hypothesis testing
and interval estimation 53</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.10 Hypothesis testing and confidence
interval estimation in regression 61</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.11 Proofs 72</p>

<p>&nbsp;</p>

<p><b>Chapter 2. Miscellaneous issues of liner regression</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.1 Weighted Least Squares 78</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.2 Prediction by regression 87</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.3 Regression with restrictions on
parameters 89</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.4 Consequences of missspecification: over
and underparametrization 92</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.5 Seemingly unrelated regressions 98</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.6 Computational issues of the OLS
estimation 108</p>

<p>&nbsp;</p>

<p><font size="5">Part 2. Alternative schemes of regression and methods of estimation</font></p>

<p><b>Chapter 3. Regression as conditional mean</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.1 Main assumptions 115</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.2 Properties of the OLS-estimator 115</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.3 Linear regression with stochastic
independent variables 125</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.4 Proofs 130</p>

<p>&nbsp;</p>

<p><b>Chapter 4. Regression with errors-in-variables</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.1 The model 131</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.2 Orthogonal regression 136</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.3 Method of maximum likelihood 142</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.4 Method of groups 147</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.5 Method of instrumental variables 153</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.6 Kartni-Weisman estimator 158</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.7 Comparison of different estimators 160</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4.8 Proofs 162</p>

<p>&nbsp;</p>

<p><b>Chapter 5. Robust estimation</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.1 Robust estimators of the parameter of
location 167</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.2 Simple methods of robust estimation
based on trimmed mean 172</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.3 Estimation based on L-p norm 174</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.4 M-estimation. Huber-, Andrews-, and
Ramsey-estimators 179</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.5 Comparison of different estimators via
statistical simulation 183</p>

<p>&nbsp;</p>

<p><b>Chapter 6. Multicollinearity. Biased estimation</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.1 Multicollinearity and its measures 186</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.2 Pure multicollinearity 195</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.3 Principles of biased estimation 196</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.4 Ridge estimator 204</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.5 Reduced length estimators, Stein
estimator 215</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.6 Estimators based on principal components
220</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.7 Marquardt estimator 220</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.8 Hocking estimator 230</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6.9 Estimators comparison via simulation 232</p>

<p>&nbsp;</p>

<p><font size="5">Part 3. Nonlinear regression</font></p>

<p><b>Chapter 7. Computational issues of nonlinear estimation</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.1 Main definitions 236</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.2 Existence of the LS estimator 241</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.3 Method of Gauss-Newton and its
modifications 245</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.4 Method of Levenberg and Marquardt 252</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.5 Uniqueness of the LS estimate 256</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.6 Linear approximations 259</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7.7 Proofs 263</p>

<p>&nbsp;</p>

<p><b>Chapter 8. Statistical properties of LS estimator</b></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.1 Continuity and asymptotic properties 265</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.2 Bias assessment 270</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.3 Hypothesis testing in nonlinear
regression 273</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.4 Seemingly unrelated nonlinear
regressions 282</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.5 Proofs 284</p>

<p>&nbsp;</p>

<p><b>Appendix</b>. Auxiliary formulas and facts</p>

<p><b>Literature</b></p>
</body>
</html>
